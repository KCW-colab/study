{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 04-1, 2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNOrwEIuki0IEiyuhttrVTL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRtaE2gS2lXc"
      },
      "source": [
        "# Lab-04-1 Multivaruable Linear regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMrtS5pi2hzc"
      },
      "source": [
        "import torch\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "n8eAhr9i3KcX",
        "outputId": "7e018fbe-4e90-49bf-b538-e3b989de820f"
      },
      "source": [
        "# calculate H(x)\n",
        "# hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n",
        "# hypothesis = x_train.matmul(W) + b or.mm or @\n",
        "# cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "'''\n",
        "# optimizer setting\n",
        "optimizer = optim.SGD([W, b], lr=1e-5)\n",
        "\n",
        "# using method optimizer\n",
        "optimizer.zero_grad()\n",
        "cost.backward()\n",
        "optimizer.step()\n",
        "'''"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# optimizer setting\\noptimizer = optim.SGD([W, b], lr=1e-5)\\n\\n# using method optimizer\\noptimizer.zero_grad()\\ncost.backward()\\noptimizer.step()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9voApRD3yg5"
      },
      "source": [
        "from torch import optim \n",
        "# initialize model\n",
        "W = torch.zeros((3, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "# setting optimizer\n",
        "optimizer = optim.SGD([W, b], lr = 1e-5)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejpSIJDc4iMg",
        "outputId": "0de9436f-342f-4861-c802-16280061b1ff"
      },
      "source": [
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "  # calculate H(x)\n",
        "\n",
        "  hypothesis = x_train.matmul(W) + b # or.mm or @\n",
        "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "\n",
        "\n",
        "  # using method optimizer\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "  \n",
        "  print(f'Epoch {epoch}/{nb_epochs} hypothesis: {hypothesis.squeeze().detach()}, Cost: {cost.item()}')\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/20 hypothesis: tensor([67.2578, 80.8397, 79.6523, 86.7394, 61.6605]), Cost: 9298.5205078125\n",
            "Epoch 1/20 hypothesis: tensor([104.9128, 126.0990, 124.2466, 135.3015,  96.1821]), Cost: 2915.71240234375\n",
            "Epoch 2/20 hypothesis: tensor([125.9942, 151.4381, 149.2133, 162.4896, 115.5097]), Cost: 915.0406494140625\n",
            "Epoch 3/20 hypothesis: tensor([137.7968, 165.6247, 163.1912, 177.7112, 126.3307]), Cost: 287.935791015625\n",
            "Epoch 4/20 hypothesis: tensor([144.4044, 173.5674, 171.0168, 186.2331, 132.3891]), Cost: 91.37117004394531\n",
            "Epoch 5/20 hypothesis: tensor([148.1035, 178.0143, 175.3980, 191.0042, 135.7812]), Cost: 29.75830078125\n",
            "Epoch 6/20 hypothesis: tensor([150.1744, 180.5042, 177.8508, 193.6753, 137.6805]), Cost: 10.445318222045898\n",
            "Epoch 7/20 hypothesis: tensor([151.3336, 181.8983, 179.2240, 195.1707, 138.7440]), Cost: 4.391228199005127\n",
            "Epoch 8/20 hypothesis: tensor([151.9824, 182.6789, 179.9928, 196.0079, 139.3396]), Cost: 2.493135452270508\n",
            "Epoch 9/20 hypothesis: tensor([152.3454, 183.1161, 180.4231, 196.4765, 139.6732]), Cost: 1.8976879119873047\n",
            "Epoch 10/20 hypothesis: tensor([152.5485, 183.3610, 180.6640, 196.7389, 139.8602]), Cost: 1.7105414867401123\n",
            "Epoch 11/20 hypothesis: tensor([152.6620, 183.4982, 180.7988, 196.8857, 139.9651]), Cost: 1.6514123678207397\n",
            "Epoch 12/20 hypothesis: tensor([152.7253, 183.5752, 180.8742, 196.9678, 140.0240]), Cost: 1.6323747634887695\n",
            "Epoch 13/20 hypothesis: tensor([152.7606, 183.6184, 180.9164, 197.0138, 140.0571]), Cost: 1.6259231567382812\n",
            "Epoch 14/20 hypothesis: tensor([152.7802, 183.6427, 180.9399, 197.0395, 140.0759]), Cost: 1.6234121322631836\n",
            "Epoch 15/20 hypothesis: tensor([152.7909, 183.6565, 180.9530, 197.0538, 140.0865]), Cost: 1.6221405267715454\n",
            "Epoch 16/20 hypothesis: tensor([152.7968, 183.6643, 180.9603, 197.0618, 140.0927]), Cost: 1.6212533712387085\n",
            "Epoch 17/20 hypothesis: tensor([152.7999, 183.6688, 180.9644, 197.0662, 140.0963]), Cost: 1.620499610900879\n",
            "Epoch 18/20 hypothesis: tensor([152.8014, 183.6715, 180.9666, 197.0686, 140.0985]), Cost: 1.6197700500488281\n",
            "Epoch 19/20 hypothesis: tensor([152.8020, 183.6731, 180.9677, 197.0699, 140.0999]), Cost: 1.619063138961792\n",
            "Epoch 20/20 hypothesis: tensor([152.8022, 183.6741, 180.9683, 197.0706, 140.1009]), Cost: 1.618358850479126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPooLwxI5Kdf"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MulitvariateLinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(3, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPGr3MX96I0Z",
        "outputId": "064046da-26a2-4529-d3d7-fa305117fdec"
      },
      "source": [
        "# cost\n",
        "model = MulitvariateLinearRegressionModel()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr = 1e-5)\n",
        "\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "  hypothesis = model(x_train)\n",
        "\n",
        "  cost = F.mse_loss(hypothesis, y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # 20번마다 로그 출력\n",
        "  print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost.item()))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/20 Cost: 24966.519531\n",
            "Epoch    1/20 Cost: 7830.294434\n",
            "Epoch    2/20 Cost: 2458.995850\n",
            "Epoch    3/20 Cost: 775.378235\n",
            "Epoch    4/20 Cost: 247.650421\n",
            "Epoch    5/20 Cost: 82.233879\n",
            "Epoch    6/20 Cost: 30.382351\n",
            "Epoch    7/20 Cost: 14.127405\n",
            "Epoch    8/20 Cost: 9.030161\n",
            "Epoch    9/20 Cost: 7.430291\n",
            "Epoch   10/20 Cost: 6.926650\n",
            "Epoch   11/20 Cost: 6.766608\n",
            "Epoch   12/20 Cost: 6.714253\n",
            "Epoch   13/20 Cost: 6.695689\n",
            "Epoch   14/20 Cost: 6.687715\n",
            "Epoch   15/20 Cost: 6.682986\n",
            "Epoch   16/20 Cost: 6.679368\n",
            "Epoch   17/20 Cost: 6.676106\n",
            "Epoch   18/20 Cost: 6.672880\n",
            "Epoch   19/20 Cost: 6.669703\n",
            "Epoch   20/20 Cost: 6.666547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wyr_6sUE8sA6"
      },
      "source": [
        "# Lab-04-2 Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s57TC9nt7CW-"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x_data = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "    self.y_data = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x_data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    x = torch.FloatTensor(self.x_data[idx])\n",
        "    y = torch.FloatTensor(self.y_data[idx])\n",
        "    \n",
        "    return x, y\n",
        "\n",
        "dataset = CustomDataset()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3p2K6A_9qay"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size = 2,\n",
        "    shuffle = True,\n",
        ")"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYG5nsaG-P_g",
        "outputId": "c0d15b3e-9902-4f3e-9e1e-4998200e4398"
      },
      "source": [
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "  for batch_idx, samples in enumerate(dataloader): # Get index and data of minibatch\n",
        "    x_train, y_train = samples\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    # len(dataloader) = nbr of minibatch per epoch\n",
        "    print('Epoch {:4d} / {} Batch {}/{} Cost: {:.6f}'.format(epoch, nb_epochs, batch_idx+1, len(dataloader), cost.item()))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0 / 20 Batch 1/3 Cost: 7.410288\n",
            "Epoch    0 / 20 Batch 2/3 Cost: 5.712851\n",
            "Epoch    0 / 20 Batch 3/3 Cost: 8.079886\n",
            "Epoch    1 / 20 Batch 1/3 Cost: 3.899839\n",
            "Epoch    1 / 20 Batch 2/3 Cost: 5.112433\n",
            "Epoch    1 / 20 Batch 3/3 Cost: 17.034388\n",
            "Epoch    2 / 20 Batch 1/3 Cost: 4.912605\n",
            "Epoch    2 / 20 Batch 2/3 Cost: 12.642778\n",
            "Epoch    2 / 20 Batch 3/3 Cost: 3.326661\n",
            "Epoch    3 / 20 Batch 1/3 Cost: 9.887987\n",
            "Epoch    3 / 20 Batch 2/3 Cost: 3.255727\n",
            "Epoch    3 / 20 Batch 3/3 Cost: 3.608006\n",
            "Epoch    4 / 20 Batch 1/3 Cost: 1.728249\n",
            "Epoch    4 / 20 Batch 2/3 Cost: 5.909775\n",
            "Epoch    4 / 20 Batch 3/3 Cost: 15.907969\n",
            "Epoch    5 / 20 Batch 1/3 Cost: 5.984921\n",
            "Epoch    5 / 20 Batch 2/3 Cost: 3.680815\n",
            "Epoch    5 / 20 Batch 3/3 Cost: 15.664739\n",
            "Epoch    6 / 20 Batch 1/3 Cost: 9.337677\n",
            "Epoch    6 / 20 Batch 2/3 Cost: 10.686520\n",
            "Epoch    6 / 20 Batch 3/3 Cost: 4.549736\n",
            "Epoch    7 / 20 Batch 1/3 Cost: 7.388728\n",
            "Epoch    7 / 20 Batch 2/3 Cost: 3.741075\n",
            "Epoch    7 / 20 Batch 3/3 Cost: 6.425547\n",
            "Epoch    8 / 20 Batch 1/3 Cost: 9.716617\n",
            "Epoch    8 / 20 Batch 2/3 Cost: 4.470834\n",
            "Epoch    8 / 20 Batch 3/3 Cost: 2.884389\n",
            "Epoch    9 / 20 Batch 1/3 Cost: 0.661119\n",
            "Epoch    9 / 20 Batch 2/3 Cost: 10.643313\n",
            "Epoch    9 / 20 Batch 3/3 Cost: 6.858939\n",
            "Epoch   10 / 20 Batch 1/3 Cost: 6.241464\n",
            "Epoch   10 / 20 Batch 2/3 Cost: 4.303391\n",
            "Epoch   10 / 20 Batch 3/3 Cost: 14.036762\n",
            "Epoch   11 / 20 Batch 1/3 Cost: 6.525825\n",
            "Epoch   11 / 20 Batch 2/3 Cost: 7.754646\n",
            "Epoch   11 / 20 Batch 3/3 Cost: 3.299775\n",
            "Epoch   12 / 20 Batch 1/3 Cost: 2.269369\n",
            "Epoch   12 / 20 Batch 2/3 Cost: 5.118080\n",
            "Epoch   12 / 20 Batch 3/3 Cost: 15.560073\n",
            "Epoch   13 / 20 Batch 1/3 Cost: 9.211740\n",
            "Epoch   13 / 20 Batch 2/3 Cost: 7.934273\n",
            "Epoch   13 / 20 Batch 3/3 Cost: 3.546247\n",
            "Epoch   14 / 20 Batch 1/3 Cost: 4.260911\n",
            "Epoch   14 / 20 Batch 2/3 Cost: 13.247803\n",
            "Epoch   14 / 20 Batch 3/3 Cost: 3.354214\n",
            "Epoch   15 / 20 Batch 1/3 Cost: 9.669805\n",
            "Epoch   15 / 20 Batch 2/3 Cost: 4.011939\n",
            "Epoch   15 / 20 Batch 3/3 Cost: 1.238274\n",
            "Epoch   16 / 20 Batch 1/3 Cost: 1.321270\n",
            "Epoch   16 / 20 Batch 2/3 Cost: 15.156295\n",
            "Epoch   16 / 20 Batch 3/3 Cost: 5.017283\n",
            "Epoch   17 / 20 Batch 1/3 Cost: 3.328833\n",
            "Epoch   17 / 20 Batch 2/3 Cost: 8.129611\n",
            "Epoch   17 / 20 Batch 3/3 Cost: 6.264199\n",
            "Epoch   18 / 20 Batch 1/3 Cost: 4.729294\n",
            "Epoch   18 / 20 Batch 2/3 Cost: 9.025249\n",
            "Epoch   18 / 20 Batch 3/3 Cost: 3.106288\n",
            "Epoch   19 / 20 Batch 1/3 Cost: 12.867178\n",
            "Epoch   19 / 20 Batch 2/3 Cost: 7.199397\n",
            "Epoch   19 / 20 Batch 3/3 Cost: 0.355972\n",
            "Epoch   20 / 20 Batch 1/3 Cost: 9.653941\n",
            "Epoch   20 / 20 Batch 2/3 Cost: 4.421600\n",
            "Epoch   20 / 20 Batch 3/3 Cost: 0.926424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoEMhiHw-ye6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
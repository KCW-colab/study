{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch Tutorial 2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPoz0JUZSy7vRH5XwUYCwGv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqqmQ-zV8z9F"
      },
      "source": [
        "# Compose Nueral Network model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wClLBS8s88Zc"
      },
      "source": [
        "torch.nn provide all of components for composing neural network\n",
        "\n",
        "All module of pytorch is subclass of nn.Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLJThUpD8v42"
      },
      "source": [
        "import os \n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9M38GKa9bcJ"
      },
      "source": [
        "## Getting device for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3KPJ4Zq9Xsm",
        "outputId": "5d22d914-f8a4-4a89-8115-eecdb11d885c"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmMvyPAX9pVi"
      },
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE32y4cW-W7g"
      },
      "source": [
        "Create instance of NeuralNetwork and move to device, and print structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0Y94AC4-R5k",
        "outputId": "1a1e1245-7d6e-4cd8-a039-30aff41f829c"
      },
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYWOEwlw-3HH"
      },
      "source": [
        "Do not call model.forward()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSnrdzw3-U0p",
        "outputId": "b23792ee-76c3-4288-a658-5ae67d7207d5"
      },
      "source": [
        "X = torch.rand(1, 28, 28, device = device)\n",
        "logits = model(X)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "print(f\"Predicted probability : {pred_probab}\")\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted probability : tensor([[0.0978, 0.1032, 0.0989, 0.0978, 0.0978, 0.0978, 0.0978, 0.0989, 0.1081,\n",
            "         0.1016]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
            "Predicted class: tensor([8], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2BuqSR1_BYa"
      },
      "source": [
        "## Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1wV4yQo-uHT",
        "outputId": "cdda504e-0de5-4864-a54b-db804d823ff8"
      },
      "source": [
        "input_image = torch.rand(3, 28, 28)\n",
        "print(input_image.size())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9-Y-RDe_Otp"
      },
      "source": [
        "sustian mini-batch dimension of dim=0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voq07rNE_F1q",
        "outputId": "376b885d-0284-487a-bd63-110263f98141"
      },
      "source": [
        "# nn.Flatten\n",
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "print(flat_image.size())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSoBP9Ca_MfZ",
        "outputId": "a181dbb0-c5f8-4717-f786-e8252b224cfc"
      },
      "source": [
        "# nn.Linear\n",
        "\n",
        "layer1 = nn.Linear(in_features = 28*28, out_features=20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfa9pLwm_ejs",
        "outputId": "346032c2-eda4-49fe-89dd-8185fbceba69"
      },
      "source": [
        "# nn.ReLU\n",
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"Ater ReLU: {hidden1}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before ReLU: tensor([[ 0.2926,  1.0303, -0.0877,  0.2363, -0.3285, -0.3749,  0.1224, -0.0027,\n",
            "          0.1360,  0.2933,  0.1547, -0.4837, -0.6447,  0.3367, -0.2275, -0.1536,\n",
            "          0.0609, -0.3961, -0.0052,  0.0616],\n",
            "        [ 0.3709,  0.7450,  0.0831,  0.6098, -0.4641, -0.0414, -0.0506,  0.0745,\n",
            "         -0.0319,  0.2704,  0.1502, -0.5864, -0.0793, -0.1945, -0.2818,  0.3000,\n",
            "          0.0265, -0.2618, -0.0499,  0.1321],\n",
            "        [ 0.4215,  0.9400, -0.3301,  0.2909, -0.2525,  0.1410,  0.0050,  0.0733,\n",
            "          0.1948,  0.0424,  0.1537, -0.5199,  0.0779,  0.2661,  0.2082,  0.2866,\n",
            "         -0.0782, -0.1430,  0.3006,  0.2886]], grad_fn=<AddmmBackward>)\n",
            "\n",
            "\n",
            "Ater ReLU: tensor([[0.2926, 1.0303, 0.0000, 0.2363, 0.0000, 0.0000, 0.1224, 0.0000, 0.1360,\n",
            "         0.2933, 0.1547, 0.0000, 0.0000, 0.3367, 0.0000, 0.0000, 0.0609, 0.0000,\n",
            "         0.0000, 0.0616],\n",
            "        [0.3709, 0.7450, 0.0831, 0.6098, 0.0000, 0.0000, 0.0000, 0.0745, 0.0000,\n",
            "         0.2704, 0.1502, 0.0000, 0.0000, 0.0000, 0.0000, 0.3000, 0.0265, 0.0000,\n",
            "         0.0000, 0.1321],\n",
            "        [0.4215, 0.9400, 0.0000, 0.2909, 0.0000, 0.1410, 0.0050, 0.0733, 0.1948,\n",
            "         0.0424, 0.1537, 0.0000, 0.0779, 0.2661, 0.2082, 0.2866, 0.0000, 0.0000,\n",
            "         0.3006, 0.2886]], grad_fn=<ReluBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbIOQG6r_qak"
      },
      "source": [
        "# nn.Sequential\n",
        "\n",
        "seq_modules = nn.Sequential(\n",
        "    flatten,\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "input_image = torch.rand(3, 28, 28)\n",
        "logits = seq_modules(input_image)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWV6liPz_7-7"
      },
      "source": [
        "# nn.Softmax\n",
        "# parameter dim is dimension of sum that is 1\n",
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probab = softmax(logits)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGODz9VSADMB",
        "outputId": "e9d9af5d-4ede-4e81-da90-001168b2bf8c"
      },
      "source": [
        "# Parameter of Model\n",
        "\n",
        "print(\"Model structure: \", model, \"\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "  print(f\"Layer: {name} | Size : {param.size()} | Values : {param[:2]} \\n\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model structure:  NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            ") \n",
            "\n",
            "\n",
            "Layer: linear_relu_stack.0.weight | Size : torch.Size([512, 784]) | Values : tensor([[-0.0121,  0.0042, -0.0092,  ...,  0.0201,  0.0266,  0.0209],\n",
            "        [ 0.0324,  0.0206, -0.0276,  ...,  0.0033,  0.0278,  0.0249]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size : torch.Size([512]) | Values : tensor([ 0.0281, -0.0014], device='cuda:0', grad_fn=<SliceBackward>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size : torch.Size([512, 512]) | Values : tensor([[-0.0020,  0.0364,  0.0045,  ..., -0.0426,  0.0280, -0.0052],\n",
            "        [-0.0085,  0.0044,  0.0400,  ..., -0.0399, -0.0180, -0.0029]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size : torch.Size([512]) | Values : tensor([0.0173, 0.0249], device='cuda:0', grad_fn=<SliceBackward>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size : torch.Size([10, 512]) | Values : tensor([[-0.0140, -0.0300, -0.0371,  ..., -0.0008,  0.0270,  0.0203],\n",
            "        [ 0.0223, -0.0397,  0.0062,  ...,  0.0299,  0.0054, -0.0060]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size : torch.Size([10]) | Values : tensor([0.0419, 0.0258], device='cuda:0', grad_fn=<SliceBackward>) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZZh6rPfCDR5"
      },
      "source": [
        "# Automatic differentiate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5MMREstBKv3"
      },
      "source": [
        "import torch\n",
        "\n",
        "x = torch.ones(5) # input tensor\n",
        "y = torch.zeros(3) # expected output\n",
        "w = torch.randn(5, 3, requires_grad = True)\n",
        "b = torch.randn(3, requires_grad = True)\n",
        "# for calculate grad of loss\n",
        "z = torch.matmul(x, w) + b\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXF4H9-qFJDl",
        "outputId": "79c9253f-bc2a-4a81-dab9-835fa676c9a3"
      },
      "source": [
        "# reference of backprobagation gradient is saved in grad_fn\n",
        "print(\"Gradient function for z = \", z.grad_fn)\n",
        "print(\"Gradinet function for loss = \", loss.grad_fn)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient function for z =  <AddBackward0 object at 0x7f36b4f19c10>\n",
            "Gradinet function for loss =  <BinaryCrossEntropyWithLogitsBackward object at 0x7f36b4f19d90>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvkpkU9sGQko"
      },
      "source": [
        "We only can get the grad of leaf which the requires_grad attribute is set to True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXCwa8yYF_NA",
        "outputId": "00ea0afc-32b8-40c8-e9f5-26adeea57190"
      },
      "source": [
        "# Calculate Gradient\n",
        "# call is code\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3107, 0.3064, 0.0399],\n",
            "        [0.3107, 0.3064, 0.0399],\n",
            "        [0.3107, 0.3064, 0.0399],\n",
            "        [0.3107, 0.3064, 0.0399],\n",
            "        [0.3107, 0.3064, 0.0399]])\n",
            "tensor([0.3107, 0.3064, 0.0399])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNEI_hAOGIFx",
        "outputId": "6e8e1134-c5de-4fc2-e190-f130a87576e5"
      },
      "source": [
        "# Stop tracking the gradient\n",
        "\n",
        "z = torch.matmul(x, w) + b\n",
        "print(z.requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "  z = torch.matmul(x, w) + b\n",
        "\n",
        "print(z.requires_grad)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBfpfOOyG3Zj",
        "outputId": "0bed85d4-d890-40e3-d21d-53453a8741d6"
      },
      "source": [
        "# Same output\n",
        "\n",
        "z = torch.matmul(x, w) + b\n",
        "z_det = z.detach()\n",
        "print(z_det.requires_grad)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS1Pn6ZFHEzZ"
      },
      "source": [
        "## Additional information of Operation Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFAyCiALG_YI",
        "outputId": "35b730f4-4205-4fdd-97ad-d8fc1a47b534"
      },
      "source": [
        "# Optional Reading : degree of tensor change and Jacobian Product\n",
        "\n",
        "inp = torch.eye(5, requires_grad = True)\n",
        "out = (inp+1).pow(2)\n",
        "\n",
        "out.backward(torch.ones_like(inp), retain_graph = True)\n",
        "print(\"First call\\n\", inp.grad)\n",
        "# degree of tensor change changes if call backward with same parameter\n",
        "out.backward(torch.ones_like(inp), retain_graph = True)\n",
        "print(\"\\nSecond call\\n\", inp.grad)\n",
        "# So we must make grad atrribute 0 first.\n",
        "# In real training, optimizer help this process\n",
        "inp.grad.zero_()\n",
        "out.backward(torch.ones_like(inp), retain_graph = True)\n",
        "print(\"\\nCall after zeroing gradients\\n\", inp.grad)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First call\n",
            " tensor([[4., 2., 2., 2., 2.],\n",
            "        [2., 4., 2., 2., 2.],\n",
            "        [2., 2., 4., 2., 2.],\n",
            "        [2., 2., 2., 4., 2.],\n",
            "        [2., 2., 2., 2., 4.]])\n",
            "\n",
            "Second call\n",
            " tensor([[8., 4., 4., 4., 4.],\n",
            "        [4., 8., 4., 4., 4.],\n",
            "        [4., 4., 8., 4., 4.],\n",
            "        [4., 4., 4., 8., 4.],\n",
            "        [4., 4., 4., 4., 8.]])\n",
            "\n",
            "Call after zeroing gradients\n",
            " tensor([[4., 2., 2., 2., 2.],\n",
            "        [2., 4., 2., 2., 2.],\n",
            "        [2., 2., 4., 2., 2.],\n",
            "        [2., 2., 2., 4., 2.],\n",
            "        [2., 2., 2., 2., 4.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02REBrKYKNfm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
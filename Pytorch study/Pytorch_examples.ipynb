{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch examples.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMQWG/E78SuS3QV/X6oEky4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXGcntvP5xKx"
      },
      "source": [
        "https://tutorials.pytorch.kr/beginner/pytorch_with_examples.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Gxzv5VzdCoI",
        "outputId": "5f011507-120f-48ae-d4cc-431c914a7610"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# generate random input and output\n",
        "x = np.linspace(-math.pi, math.pi, 2000)\n",
        "y = np.sin(x)\n",
        "\n",
        "# randomly initialize weight\n",
        "a = np.random.randn()\n",
        "b = np.random.randn()\n",
        "c = np.random.randn()\n",
        "d = np.random.randn()\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(2000):\n",
        "  # predict y\n",
        "  # y = a + bx + cx^2 + dx^3\n",
        "  y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
        "\n",
        "  # caculate loss and print\n",
        "  loss = np.square(y_pred - y).sum()\n",
        "  if t % 100 == 99:\n",
        "    print(t, loss)\n",
        "\n",
        "  # caculating gradient of a, b, c, d by loss and backpropagation\n",
        "  grad_y_pred = 2.0 * (y_pred - y)\n",
        "  grad_a = grad_y_pred.sum()\n",
        "  grad_b = (grad_y_pred * x).sum()\n",
        "  grad_c = (grad_y_pred * x ** 2).sum()\n",
        "  grad_d = (grad_y_pred * x ** 3).sum()\n",
        "\n",
        "  # renew weight\n",
        "  a -= learning_rate * grad_a\n",
        "  b -= learning_rate * grad_b\n",
        "  c -= learning_rate * grad_c\n",
        "  d -= learning_rate * grad_d\n",
        "\n",
        "print(f'Result : y = {a} + {b} x + {c} x^2 + {d} x^3')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 2925.306170856854\n",
            "199 1998.8177004175175\n",
            "299 1368.2065699536292\n",
            "399 938.4974623665523\n",
            "499 645.3527262284896\n",
            "599 445.1421735434525\n",
            "699 308.24618225999734\n",
            "799 214.53447807516284\n",
            "899 150.31074162200264\n",
            "999 106.24571075189287\n",
            "1099 75.9775249230035\n",
            "1199 55.16290732374333\n",
            "1299 40.83327382993528\n",
            "1399 30.957294221960858\n",
            "1499 24.143380418804668\n",
            "1599 19.43711487691226\n",
            "1699 16.18316604241915\n",
            "1799 13.931054447857244\n",
            "1899 12.370770304251756\n",
            "1999 11.28873562040335\n",
            "Result : y = 0.04560869543490431 + 0.8326347986221017 x + -0.007868258894488906 x^2 + -0.08990151413462892 x^3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u-BvORG2625",
        "outputId": "36bb4e39-5acd-4328-c18a-7f71d5049146"
      },
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "# device = torch.device(\"cuda:0\") if you want gpu\n",
        "\n",
        "# generate input, output tensor\n",
        "# default : requires_grad = False\n",
        "\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device = device, dtype = dtype)\n",
        "y = torch.sin(x)\n",
        "\n",
        "a = torch.randn((), device = device, dtype = dtype , requires_grad = True)\n",
        "b = torch.randn((), device = device, dtype = dtype , requires_grad = True)\n",
        "c = torch.randn((), device = device, dtype = dtype , requires_grad = True)\n",
        "d = torch.randn((), device = device, dtype = dtype , requires_grad = True)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(2000):\n",
        "  y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
        "\n",
        "  loss = (y_pred - y).pow(2).sum()\n",
        "  if t % 100 == 99:\n",
        "    print(t, loss.item())\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    a -= learning_rate * a.grad\n",
        "    b -= learning_rate * b.grad\n",
        "    c -= learning_rate * c.grad\n",
        "    d -= learning_rate * d.grad\n",
        "\n",
        "    # after renew weight, make 0 the degree of gradient\n",
        "    a.grad = None\n",
        "    b.grad = None\n",
        "    c.grad = None\n",
        "    d.grad = None\n",
        "    \n",
        "print(f'Result : y = {a.item()}  + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 4224.29296875\n",
            "199 2796.306640625\n",
            "299 1852.0491943359375\n",
            "399 1227.6573486328125\n",
            "499 814.7772827148438\n",
            "599 541.7596435546875\n",
            "699 361.2262268066406\n",
            "799 241.84835815429688\n",
            "899 162.9095001220703\n",
            "999 110.71099853515625\n",
            "1099 76.19458770751953\n",
            "1199 53.37056350708008\n",
            "1299 38.27825927734375\n",
            "1399 28.298442840576172\n",
            "1499 21.699230194091797\n",
            "1599 17.335481643676758\n",
            "1699 14.44990062713623\n",
            "1799 12.541831970214844\n",
            "1899 11.280084609985352\n",
            "1999 10.44577407836914\n",
            "Result : y = 0.00036133499816060066  + 0.8175127506256104 x + -6.233552994672209e-05 x^2 + -0.08775053173303604 x^3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmkrgYBBs1sk"
      },
      "source": [
        "autograd Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTWy1wKE5Ss3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef3ef2f7-6ad3-44a9-c161-4c715faae262"
      },
      "source": [
        "import torch\n",
        "import numpy\n",
        "import math\n",
        "\n",
        "\n",
        "class LegendrePolyomial3(torch.autograd.Function):\n",
        "  '''\n",
        "  inherite torch.autograd.Function and implement autograd Function,\n",
        "  backward and foward step.\n",
        "  '''\n",
        "\n",
        "  @staticmethod\n",
        "  def forward(ctx, input):\n",
        "    ctx.save_for_backward(input)  \n",
        "    # save any parameter for using backpropagation steps \n",
        "    return 0.5 * (5 * input ** 3 - 3 * input)     \n",
        "\n",
        "  @staticmethod\n",
        "  def backward(ctx, grad_output):\n",
        "\n",
        "    input, = ctx.saved_tensors\n",
        "    return grad_output * 1.5 * (5 * input ** 2 - 1)\n",
        "\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device('cpu')\n",
        "# device = torch.device(\"cuda:0\")\n",
        "\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device = device, dtype=dtype)\n",
        "y = torch.sin(x)\n",
        "\n",
        "a = torch.full((), 0.0, device = device, dtype = dtype, requires_grad=True)\n",
        "b = torch.full((), -1.0, device = device, dtype = dtype, requires_grad=True)\n",
        "c = torch.full((), 0.0, device = device, dtype = dtype, requires_grad=True)\n",
        "d = torch.full((), 0.3, device = device, dtype = dtype, requires_grad=True)\n",
        "\n",
        "learning_rate = 5e-6\n",
        "for t in range(2000):\n",
        "  P3 = LegendrePolyomial3.apply\n",
        "\n",
        "  y_pred = a + b * P3(c + d * x)\n",
        "\n",
        "  loss = (y_pred - y).pow(2).sum()\n",
        "  if t % 100 == 99:\n",
        "    print(t, loss.item())\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    a -= learning_rate * a.grad\n",
        "    b -= learning_rate * b.grad\n",
        "    c -= learning_rate * c.grad\n",
        "    d -= learning_rate * d.grad\n",
        "\n",
        "  a.grad = None\n",
        "  b.grad = None\n",
        "  c.grad = None\n",
        "  d.grad = None\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} * P3({c.item()} + {d.item()} x)')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 209.95834350585938\n",
            "199 144.66018676757812\n",
            "299 100.70249938964844\n",
            "399 71.03519439697266\n",
            "499 50.97850799560547\n",
            "599 37.403133392333984\n",
            "699 28.206867218017578\n",
            "799 21.97318458557129\n",
            "899 17.7457275390625\n",
            "999 14.877889633178711\n",
            "1099 12.93176555633545\n",
            "1199 11.610918998718262\n",
            "1299 10.71425724029541\n",
            "1399 10.10548210144043\n",
            "1499 9.692106246948242\n",
            "1599 9.411375045776367\n",
            "1699 9.220745086669922\n",
            "1799 9.091285705566406\n",
            "1899 9.003360748291016\n",
            "1999 8.943639755249023\n",
            "Result: y = -5.394172664097141e-09 + -2.208526849746704 * P3(1.367587154632588e-09 + 0.2554861009120941 x)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36zessrFszf5"
      },
      "source": [
        "nn module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk0NXCqNPL1T",
        "outputId": "7e132a58-ef03-46b0-9cef-079d87d85593"
      },
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# Since y is linear function, we can think linear step neural network\n",
        "# Ready tensor for (x, x^2, x^3)\n",
        "\n",
        "p = torch.tensor([1, 2, 3])\n",
        "xx = x.unsqueeze(-1).pow(p)\n",
        "\n",
        "# shape of xx is (2000, 3)\n",
        "\n",
        "# Define the model as sequence of layers using nn pakage\n",
        "# nn.Sequential is a module that contains other modules, which apply them sequentially to produce output.\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(3, 1),\n",
        "    torch.nn.Flatten(0, 1)\n",
        "    # flatten the output of linear layer for matching 'y' shape(1D tensor)\n",
        ")\n",
        "\n",
        "loss_fn = torch.nn.MSELoss(reduction = 'sum') \n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(2000):\n",
        "  y_pred = model(xx)\n",
        "\n",
        "  loss = loss_fn(y_pred, y)\n",
        "  if t % 100 == 99:\n",
        "    print(t, loss.item())\n",
        "\n",
        "  # For implement backpropagation, make gradient 0.\n",
        "  model.zero_grad()\n",
        "\n",
        "  # calculate gradient of loss\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for param in model.parameters():\n",
        "      param -= learning_rate * param.grad\n",
        "\n",
        "linear_layer = model[0]\n",
        "\n",
        "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 856.858642578125\n",
            "199 576.7860717773438\n",
            "299 389.48284912109375\n",
            "399 264.13873291015625\n",
            "499 180.2006072998047\n",
            "599 123.95048522949219\n",
            "699 86.22711181640625\n",
            "799 60.908931732177734\n",
            "899 43.90278244018555\n",
            "999 32.47048568725586\n",
            "1099 24.778440475463867\n",
            "1199 19.598384857177734\n",
            "1299 16.10674476623535\n",
            "1399 13.751002311706543\n",
            "1499 12.160022735595703\n",
            "1599 11.08452033996582\n",
            "1699 10.35669994354248\n",
            "1799 9.863639831542969\n",
            "1899 9.529302597045898\n",
            "1999 9.30233097076416\n",
            "Result: y = -0.015610501170158386 + 0.8408371210098267 x + 0.002693071262910962 x^2 + -0.09106822311878204 x^3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYsVcgFLv2_J"
      },
      "source": [
        "optim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Apv4Q4SHvxYo",
        "outputId": "ce8c3fd3-016f-4868-b76e-ec0a4d2bebab"
      },
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "p = torch.tensor([1, 2, 3])\n",
        "xx = x.unsqueeze(-1).pow(p)\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(3, 1),\n",
        "    torch.nn.Flatten(0, 1)\n",
        ")\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "# First parameter of RMSprop tells you which tensor should be updated.\n",
        "learning_rate = 1e-3\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate)\n",
        "\n",
        "for t in range(2000):\n",
        "  y_pred = model(xx)\n",
        "\n",
        "  loss = loss_fn(y_pred, y)\n",
        "  if t % 100 == 99:\n",
        "    print(t, loss.item())\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "linear_layer = model[0]\n",
        "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 5490.78857421875\n",
            "199 1112.47705078125\n",
            "299 178.72592163085938\n",
            "399 78.5672378540039\n",
            "499 67.14202880859375\n",
            "599 56.2918586730957\n",
            "699 43.62319564819336\n",
            "799 30.328166961669922\n",
            "899 19.13492202758789\n",
            "999 12.201615333557129\n",
            "1099 9.418639183044434\n",
            "1199 8.854554176330566\n",
            "1299 8.817550659179688\n",
            "1399 8.817341804504395\n",
            "1499 8.839642524719238\n",
            "1599 8.91847038269043\n",
            "1699 8.887210845947266\n",
            "1799 8.873652458190918\n",
            "1899 8.9132661819458\n",
            "1999 8.942415237426758\n",
            "Result: y = -0.0005039672832936049 + 0.8561848402023315 x + -0.0005039726966060698 x^2 + -0.09388662129640579 x^3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LpYyGakxWbW"
      },
      "source": [
        "Custom nn.Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3IfCvJewnPI",
        "outputId": "cb372bc7-d700-4f73-88f7-a505bebbdf45"
      },
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "class Polynomial3(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.a = torch.nn.Parameter(torch.randn(()))\n",
        "    self.b = torch.nn.Parameter(torch.randn(()))\n",
        "    self.c = torch.nn.Parameter(torch.randn(()))\n",
        "    self.d = torch.nn.Parameter(torch.randn(()))\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3\n",
        "\n",
        "  def string(self):\n",
        "    return f'y = {self.a.item()} + {self.b.item()} x + {self.c.item()} x^2 + {self.d.item()} x^3'\n",
        "\n",
        "\n",
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "model = Polynomial3()\n",
        "\n",
        "criterion = torch.nn.MSELoss(reduction = 'sum')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-6)\n",
        "for t in range(2000):\n",
        "  y_pred = model(x)\n",
        "\n",
        "  loss = criterion(y_pred, y)\n",
        "  if t % 100 == 99:\n",
        "    print(t, loss.item())\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print(f'Result: {model.string()}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 97.65093231201172\n",
            "199 68.128173828125\n",
            "299 48.440940856933594\n",
            "399 35.30442428588867\n",
            "499 26.534313201904297\n",
            "599 20.675945281982422\n",
            "699 16.760162353515625\n",
            "799 14.141233444213867\n",
            "899 12.388460159301758\n",
            "999 11.214608192443848\n",
            "1099 10.427906036376953\n",
            "1199 9.900266647338867\n",
            "1299 9.546106338500977\n",
            "1399 9.308185577392578\n",
            "1499 9.14823055267334\n",
            "1599 9.040600776672363\n",
            "1699 8.968099594116211\n",
            "1799 8.919228553771973\n",
            "1899 8.88625431060791\n",
            "1999 8.863980293273926\n",
            "Result: y = -0.0043967105448246 + 0.8514556288719177 x + 0.0007585037383250892 x^2 + -0.09257861226797104 x^3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEQECiIryRra"
      },
      "source": [
        "Control Flow + Weight Sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwhWgX3EyPI2",
        "outputId": "5b59fce4-5aca-4d12-d18b-578e3ae641d1"
      },
      "source": [
        "import torch\n",
        "import math\n",
        "import random\n",
        "\n",
        "class DynamicNet(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.a = torch.nn.Parameter(torch.randn(()))\n",
        "    self.b = torch.nn.Parameter(torch.randn(()))\n",
        "    self.c = torch.nn.Parameter(torch.randn(()))\n",
        "    self.d = torch.nn.Parameter(torch.randn(()))\n",
        "    self.e = torch.nn.Parameter(torch.randn(()))\n",
        "  \n",
        "  def forward(self, x):\n",
        "    y = self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3\n",
        "    for exp in range(4, random.randint(4, 6)):\n",
        "      y = y + self.e * x ** exp\n",
        "    return y\n",
        "\n",
        "  def string(self):\n",
        "    return f'y = {self.a.item()} + {self.b.item()} x + {self.c.item()} x^2 + {self.d.item()} x^3 + {self.e.item()} x^4 ? + {self.e.item()} x^5 ?'\n",
        "\n",
        "\n",
        "\n",
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "\n",
        "model = DynamicNet()\n",
        "\n",
        "criterion = torch.nn.MSELoss(reduction = 'sum')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-8, momentum = 0.9)\n",
        "# Since training is so hard, use momentum.\n",
        "\n",
        "for t in range(30000):\n",
        "  y_pred = model(x)\n",
        "\n",
        "  loss = criterion(y_pred, y)\n",
        "  if t % 2000 == 1999:\n",
        "    print(t, loss.item())\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print(f\"Result: {model.string()}\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1999 1668.876953125\n",
            "3999 743.2471313476562\n",
            "5999 337.8854675292969\n",
            "7999 158.88058471679688\n",
            "9999 77.25334167480469\n",
            "11999 39.827362060546875\n",
            "13999 573.9304809570312\n",
            "15999 15.176431655883789\n",
            "17999 11.811789512634277\n",
            "19999 10.145736694335938\n",
            "21999 9.276951789855957\n",
            "23999 8.9099760055542\n",
            "25999 8.955068588256836\n",
            "27999 8.888725280761719\n",
            "29999 8.633642196655273\n",
            "Result: y = 0.005159955006092787 + 0.8541369438171387 x + -0.0014319702750071883 x^2 + -0.09319084882736206 x^3 + 0.00011997557885479182 x^4 ? + 0.00011997557885479182 x^5 ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf70gvvGzLJW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs231n Training Neural Networks II.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "r9rgbs6jSqsL",
        "outputId": "17468624-0df6-487c-9ef1-85b319c4e692"
      },
      "source": [
        "# SGD\n",
        "\n",
        "\"\"\"\n",
        "while True:\n",
        "  dx = compute_gradient(x)\n",
        "  x += learning_rate * dx\n",
        "\"\"\"\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nwhile True:\\n  dx = compute_gradient(x)\\n  x += learning_rate * dx\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Cv3WLIzNSvrK",
        "outputId": "44b7727d-0154-42be-8b06-ef560902b6f4"
      },
      "source": [
        "# SGD + Momentum\n",
        "\n",
        "\"\"\"\n",
        "vx = 0\n",
        "while True:\n",
        "  dx = compute_gradient(x)\n",
        "  vx = rho * vs + dx\n",
        "  x += learning_rate * vx\n",
        "\"\"\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nvx = 0\\nwhile True:\\n  dx = compute_gradient(x)\\n  vx = rho * vs + dx\\n  x += learning_rate * vx\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "E5eiMZPpTAKR",
        "outputId": "0640ced1-9672-4d5d-d946-538ec1841255"
      },
      "source": [
        "# AdaGrad\n",
        "\n",
        "\"\"\"\n",
        "grad_squared = 0\n",
        "while True:\n",
        "  dx = compute_gradient(x)\n",
        "  grad_squared += dx * dx\n",
        "  x -= learning_rate * dx / (np.sqrt(gradient) + 1e-7)\n",
        "\"\"\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ngrad_squared = 0\\nwhile True:\\n  dx = compute_gradient(x)\\n  grad_squared += dx * dx\\n  x -= learning_rate * dx / (np.sqrt(gradient) + 1e-7)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bKwOttMUEZE"
      },
      "source": [
        "# RMSProp\n",
        "\n",
        "\"\"\"\n",
        "grad_squared = 0\n",
        "while True:\n",
        "  dx = compute_gradient(x)\n",
        "  grad_squared += decay_rate * grad_squared + (1 - decay_rate) * dx * dx \n",
        "  x -= learning_rate * dx / (np.sqrt(gradient) + 1e-7)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zuRodI5XVrT9",
        "outputId": "274c3d53-b252-4007-ee8b-bf38fc46b05a"
      },
      "source": [
        "# Adam(almost)\n",
        "\n",
        "'''\n",
        "first_moment = 0\n",
        "second_moment = 0\n",
        "while True:\n",
        "  dx = compute_gradient(x)\n",
        "  first_moment = beta1 * first_moment + (1 - beta1) * dx\n",
        "  second_moment = beta2 * second_moment + (1 - beta2) * dx * dx\n",
        "  x -= learning_rate * first_moment / (np.sqrt(second_moment) + 1e-7)\n",
        "'''"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfirst_moment = 0\\nsecond_moment = 0\\nwhile True:\\n  dx = compute_gradient(x)\\n  first_moment = beta1 * first_moment + (1 - beta1) * dx\\n  second_moment = beta2 * second_moment + (1 - beta2) * dx * dx\\n  x -= learning_rate * first_moment / (np.sqrt(second_moment) + 1e-7)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "qB-gI5lkWRTH",
        "outputId": "22879d9a-5719-403b-a7a7-1f99051a5e8c"
      },
      "source": [
        "# Adam(full form)\n",
        "\n",
        "'''\n",
        "first_moment = 0\n",
        "second_moment = 0\n",
        "for t in range(num_iterations):\n",
        "  dx = compute_gradient(x)\n",
        "  first_moment = beta1 * first_moment + (1 - beta1) * dx\n",
        "  second_moment = beta2 * second_moment + (1 - beta2) * dx * dx\n",
        "  first_unbias = first_moment / (1 - beta1 ** t)\n",
        "  second_unbias = second_moment / (1- beta2 ** t)\n",
        "  x -= learning_rate * first_unbias / (np.sqrt(second_unbias) + 1e-7)\n",
        "'''"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfirst_moment = 0\\nsecond_moment = 0\\nfor t in range(num_iterations):\\n  dx = compute_gradient(x)\\n  first_moment = beta1 * first_moment + (1 - beta1) * dx\\n  second_moment = beta2 * second_moment + (1 - beta2) * dx * dx\\n  first_unbias = first_moment / (1 - beta1 ** t)\\n  second_unbias = second_moment / (1- beta2 ** t)\\n  x -= learning_rate * first_unbias / (np.sqrt(second_unbias) + 1e-7)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgt6yyltXuIp"
      },
      "source": [
        "# Regularization : Dropout\n",
        "# Vanilla Dropout : Not recommended implementation (see notes below)\n",
        "\n",
        "p = 0.5 # probability of keeping a unit active. higher = less dropout\n",
        "\n",
        "def train_step(X):\n",
        "  \"\"\" X contains the data \"\"\"\n",
        "  \n",
        "  # forward pass for example 3-layer neural network\n",
        "  H1 = np.maximum(0, np.dot(W1, X) + b1)\n",
        "  U1 = np.random.rand(*H1.shape) < p # first dropout mask\n",
        "  H1 *= U1 # drop!\n",
        "  H2 = np.maximum(0, np.dot(W2, H1) + b2)\n",
        "  U2 = np.random.rand(*H2.shape) < p # second dropout mask\n",
        "  H2 *= U2 # drop!\n",
        "  out = np.dot(W3, H2) + b3\n",
        "\n",
        "  # backward pass : compute gradients...(not shown)\n",
        "  # perform parameter update... (not shown)\n",
        "\n",
        "def predict(X):\n",
        "  # ensembled forward pass\n",
        "  H1 = np.maximum(0, np.dot(W1, X) + b1) * p # NOTE: scale the activation\n",
        "  H2 = np.maximum(0, np.dot(W2, H1) + b2) * p # NOTe: scale the activation\n",
        "  out = np.dot(W3, H2) + b3"
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}
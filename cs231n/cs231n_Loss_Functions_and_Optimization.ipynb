{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs231n Loss Functions and Optimization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_V6mHFF4Zjq"
      },
      "source": [
        "- **Multiclass SVM Loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8l0k3nH4VbR"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def L_i_vectorized(x, y ,W):\n",
        "  scores = W.dot(x)\n",
        "  margins = np.maximum(0, scores - scores[y] + 1)\n",
        "  margins[y] = 0 # y번째 클래스가 정답 클래스 이므로 이렇게 지정\n",
        "  loss_i = np.sum(margins)\n",
        "  return loss_i\n",
        "\n",
        "# y번째 클래스(정답 클래스)와의 loss들을 계산하는 방법.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcbxS1eNApTj"
      },
      "source": [
        "- **Random search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P9eNGF84r5k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "2085d188-fd78-4b5b-df09-08426b955798"
      },
      "source": [
        "''' \n",
        "# assume X_train is the data where each column is an example (e.g 3073 x 50,000)\n",
        "# assume Y_train are the labels (e.g 1D array of 50,000)\n",
        "# assume the function L evaluates the loss function\n",
        "bestloss = float(\"inf\") # Python assigns the highest possible float value\n",
        "\n",
        "for num in ragnge(1000):\n",
        "  W = np.random.randn(10, 3073) * 0.0001 # generate random parameters\n",
        "  loss = L(X_train, Y_train, W) # get the loss over the entrie training set\n",
        "  if loss < bestloss: # keep track of the best solution\n",
        "    bestloss = loss\n",
        "    bestW = W\n",
        "  print('in attempt %d the loss was %f, best %f'%(num, loss, bestloss))\n",
        "\n",
        "scores = Wbest.dot(Xte_cols)\n",
        "Yte_predict = np.argmax(scores, axis = 0)\n",
        "np.mean(Yte_predict == Yte)\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' \\n# assume X_train is the data where each column is an example (e.g 3073 x 50,000)\\n# assume Y_train are the labels (e.g 1D array of 50,000)\\n# assume the function L evaluates the loss function\\nbestloss = float(\"inf\") # Python assigns the highest possible float value\\n\\nfor num in ragnge(1000):\\n  W = np.random.randn(10, 3073) * 0.0001 # generate random parameters\\n  loss = L(X_train, Y_train, W) # get the loss over the entrie training set\\n  if loss < bestloss: # keep track of the best solution\\n    bestloss = loss\\n    bestW = W\\n  print(\\'in attempt %d the loss was %f, best %f\\'%(num, loss, bestloss))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKNfDndbLe4w"
      },
      "source": [
        "- **Gradient Descent**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "bQvJQ9X9Bh-O",
        "outputId": "98e416f2-6e73-41d5-96e6-0f994228d9fd"
      },
      "source": [
        "# Vanilla Gradient Descent\n",
        "'''\n",
        "while True:\n",
        "  weights_grad = evaluate_gradient(loss_fun, data, weights)\n",
        "  weights += - step_size * weights_grad # perform parameter update\n",
        "  # step_size = Learning rate\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nwhile True:\\n  weights_grad = evaluate_gradient(loss_fun, data, weights)\\n  weights += - step_size * weights_grad # perform parameter update\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU0QaAHUNKJP"
      },
      "source": [
        "- **Stochastic Gradient Descent(SGD)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "1Z3Uu36MLsVh",
        "outputId": "16441270-59b9-4a19-d22b-364da11e50e7"
      },
      "source": [
        "# Vanilla Minibatch Gradient Descent\n",
        "'''\n",
        "while True:\n",
        "  data_batch = sample_training_data(data, 256) # sample 256 examples\n",
        "  weights_grad = evaluate_gradient(loss_fun, data_batch, weights)\n",
        "  weights += - step_size * weights_grad # perform parameter update\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nwhile True:\\n  data_batch = sample_training_data(data, 256) # sample 256 examples\\n  weights_grad = evaluate_gradient(loss_fun, data_batch, weights)\\n  weights += - step_size * weights_grad # perform parameter update\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxkAblUwNnr8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}